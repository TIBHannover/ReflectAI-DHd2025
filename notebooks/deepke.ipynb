{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers accelerate bitsandbytes>0.37.0 -q"
      ],
      "metadata": {
        "id": "jgVdG_9UHP98"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GenerationConfig"
      ],
      "metadata": {
        "id": "-gpVPS-cLlce"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import (\n",
        "    AutoConfig,\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    BitsAndBytesConfig,\n",
        ")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_path = \"zjunlp/OneKE\"\n",
        "config = AutoConfig.from_pretrained(model_path, trust_remote_code=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_path, trust_remote_code=True\n",
        ")\n",
        "\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    llm_int8_threshold=6.0,\n",
        "    llm_int8_has_fp16_weight=False,\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_path,\n",
        "    config=config,\n",
        "    device_map=\"auto\",\n",
        "    quantization_config=quantization_config,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "oYHP14NNHR9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rewrite_triplets(triplets):\n",
        "    relation_wikidata = {\n",
        "        \"main subject\": \"wdt:P921\",\n",
        "        \"genre\": None,\n",
        "        \"creator\": \"wdt:P170\",\n",
        "        \"located in\": \"wdt:P276\",\n",
        "        \"made from material\": \"wdt:P186\",\n",
        "        \"location of creation\": \"wdt:P1071\",\n",
        "        \"movement\": \"wdt:P135\",\n",
        "        \"alias\": None,\n",
        "        \"description\": \"schema:description\",\n",
        "        \"language\": None,\n",
        "        \"inception\": \"wdt:P571\",\n",
        "        \"shown with features\": \"wdt:P1354\",\n",
        "        \"depicts\": \"wdt:P180\",\n",
        "    }\n",
        "\n",
        "    reformatted = []\n",
        "    for relation, duplets in triplets.items():\n",
        "        try:\n",
        "            for duplet in duplets:\n",
        "                reformatted.append(\n",
        "                    {\n",
        "                        \"relation\": {\n",
        "                            \"label\": relation,\n",
        "                            \"wikidata_id\": relation_wikidata.get(relation, None),\n",
        "                        },\n",
        "                        \"subject\": {\"label\": duplet[\"subject\"]},\n",
        "                        \"object\": {\"label\": duplet[\"object\"]},\n",
        "                    }\n",
        "                )\n",
        "        except (TypeError, KeyError) as e:\n",
        "            print('Exception when rewriting triplets:', e)\n",
        "            continue\n",
        "\n",
        "    return reformatted"
      ],
      "metadata": {
        "id": "y9d1Qbd57ulG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = '<<SYS>>\\nYou are a helpful assistant.\\n<</SYS>>\\n\\n'\n",
        "sintruct = \"{\\\"instruction\\\": \\\"You are an expert in named entity recognition. Please extract entities that match the schema definition from the input. Return an empty list if the entity type does not exist. Please respond in the format of a JSON string.\\\", \\\"schema\\\": [\\\"person\\\", \\\"organization\\\", \\\"else\\\", \\\"location\\\"], \\\"input\\\": \\\"284 Robert Allenby ( Australia ) 69 71 71 73 , Miguel Angel Martin ( Spain ) 75 70 71 68 ( Allenby won at first play-off hole )\\\"}\"\n",
        "sintruct = '[INST] ' + system_prompt + sintruct + '[/INST]'\n",
        "\n",
        "input_ids = tokenizer.encode(sintruct, return_tensors=\"pt\").to(device)\n",
        "input_length = input_ids.size(1)\n",
        "generation_output = model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_length=1024, max_new_tokens=512, return_dict_in_generate=True))\n",
        "generation_output = generation_output.sequences[0]\n",
        "generation_output = generation_output[input_length:]\n",
        "output = tokenizer.decode(generation_output, skip_special_tokens=True)\n",
        "\n",
        "print(output)"
      ],
      "metadata": {
        "id": "zgCvg6OHHUJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load some dh resources"
      ],
      "metadata": {
        "id": "eToUF9q9_1FB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "##################### Change something here\n",
        "#master = \"https://raw.githubusercontent.com/TIBHannover/ReflectAI-DHd2025/refs/heads/main/data/Man_with_a_Book.txt\"\n",
        "#master = \"https://raw.githubusercontent.com/TIBHannover/ReflectAI-DHd2025/refs/heads/main/data/Hunter_Getting_Dress.txt\"\n",
        "#master = \"https://raw.githubusercontent.com/TIBHannover/ReflectAI-DHd2025/refs/heads/main/data/Conversion_of_Mary_M.txt\"\n",
        "#master = \"https://raw.githubusercontent.com/TIBHannover/ReflectAI-DHd2025/refs/heads/main/data/Perseus_und_Andromed.txt\"\n",
        "master = \"https://raw.githubusercontent.com/TIBHannover/ReflectAI-DHd2025/refs/heads/main/data/Portrait_of_Laura_Di.txt\"\n",
        "##################### Change something here\n",
        "\n",
        "req = requests.get(master)\n",
        "text = req.text\n",
        "print(text)"
      ],
      "metadata": {
        "id": "xxu2imWOLbGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "system_prompt = \"\"\"\n",
        "<<SYS>>\n",
        "You are a helpful assistant.\n",
        "<</SYS>>\n",
        "\"\"\"\n",
        "\n",
        "prompt = {\n",
        "    \"instruction\": \"You are an expert specializing in relation extraction. Please extract relationship triples that comply with the schema definition from the input; return an empty list for non-existent relationships. Please respond in the JSON string format.\",\n",
        "    \"schema\": {\n",
        "        ##################### Change something here\n",
        "        \"creator\": \"The name or pseudonym of the painter that created the painting.\",\n",
        "        ##################### Change something here\n",
        "    },\n",
        "    \"example\": [],\n",
        "    \"input\": text,\n",
        "}\n",
        "\"\"\"\n",
        "[/INST]\n",
        "\"\"\"\n",
        "\n",
        "prompt = json.dumps(prompt)\n",
        "sintruct = \"[INST] \" + system_prompt + prompt + \"[/INST]\""
      ],
      "metadata": {
        "id": "8za_azO6toTQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer.encode(sintruct, return_tensors=\"pt\").to(device)\n",
        "input_length = input_ids.size(1)\n",
        "generation_output = model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_length=1024, max_new_tokens=512, return_dict_in_generate=True))\n",
        "generation_output = generation_output.sequences[0]\n",
        "generation_output = generation_output[input_length:]\n",
        "output = tokenizer.decode(generation_output, skip_special_tokens=True)\n",
        "\n",
        "print(output)"
      ],
      "metadata": {
        "id": "ows8XjXfu-Xz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "triplets = rewrite_triplets(json.loads(output))"
      ],
      "metadata": {
        "id": "lbYNtfLJ5IMN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(json.dumps(triplets, indent=2))"
      ],
      "metadata": {
        "id": "Fh5fabSq75SC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}